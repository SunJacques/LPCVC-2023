{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18 training\n",
    "\n",
    "created on 20/06/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import glob\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPCVCDataset(Dataset):\n",
    "    def __init__(self, datapath, transform, n_class=14, train=True, patch=False):\n",
    "        self.datapath = datapath\n",
    "\n",
    "        self.transform = transform\n",
    "        self.n_class = n_class\n",
    "        self.train = train\n",
    "\n",
    "        self.patches = patch\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            files = glob.glob(os.path.join(self.datapath + 'train/IMG/train', \"*.png\"))\n",
    "        else:\n",
    "            files = glob.glob(os.path.join(self.datapath + 'val/LPCVC_Val/IMG/val', \"*.png\"))\n",
    "        return len(files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            img = cv2.imread(self.datapath + 'train/IMG/train/train_' + str(idx).zfill(4) + '.png')\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(self.datapath + 'train/GT_Updated/train/train_' + str(idx).zfill(4) + '.png')\n",
    "        else:\n",
    "            img = cv2.imread(self.datapath + 'val/LPCVC_Val/GT/val/val_' + str(idx).zfill(4) + '.png')\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(self.datapath + 'val/LPCVC_Val/IMG/val/val_' + str(idx).zfill(4) + '.png')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "\n",
    "        t = T.Compose([T.ToTensor(), T.Normalize(0, 1)])\n",
    "        img = t(img)\n",
    "        mask = self.onehot(mask, self.n_class)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def onehot(self, img, nb):\n",
    "        oh = np.zeros((img.shape[0], img.shape[1], nb))\n",
    "        for i in range(nb):\n",
    "            oh[:, :, i] = (img[:, :, 0] == i)\n",
    "        return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = LPCVCDataset(\"dataset/\",transform=None,  n_class=14, train=True)\n",
    "# val_dataset = LPCVCDataset(\"dataset/\", transform=None,  n_class=14, train=False)\n",
    "#\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#         dataset=train_dataset,\n",
    "#         batch_size=32,\n",
    "#         shuffle=True,\n",
    "#         num_workers=2,\n",
    "#         pin_memory=True\n",
    "# )\n",
    "#\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#         dataset=val_dataset,\n",
    "#         batch_size=32,\n",
    "#         shuffle=False,\n",
    "#         num_workers=1,\n",
    "#         pin_memory=True\n",
    "#  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(512, 512, 14)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_loader.dataset[0][1].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "(512, 512, 14)\n"
     ]
    }
   ],
   "source": [
    "# print(train_dataset[0][0].size()) # shape of input\n",
    "# print(train_dataset[0][1].shape) # shape of output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the device to use\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "created on 20/06/2023, building a resnet18 by scratch\n",
    "\"\"\"\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet_18(nn.Module):\n",
    "\n",
    "    def __init__(self, image_channels, num_classes):\n",
    "\n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "\n",
    "        ## newly added parts\n",
    "        self.upsample = nn.Upsample(scale_factor=32, mode = 'bilinear', align_corners=False)\n",
    "        self.upconv1 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.upconv2 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.upconv3 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # self.fc = nn.Linear(512, num_classes)\n",
    "        self.conv_out = nn.Conv2d(64 , num_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "\n",
    "        return nn.Sequential(\n",
    "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride),\n",
    "            Block(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = self.upconv1(x)\n",
    "        x = self.upconv2(x)\n",
    "        x = self.upconv3(x)\n",
    "        x = self.conv_out(x)\n",
    "        # x = self.avgpool(x)\n",
    "        # x = x.view(x.shape[0], -1)\n",
    "        # x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet_18(3, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.6822, -0.8482, -0.2568,  ...,  0.1321, -0.3895, -0.4931],\n          [ 0.5126, -0.5685,  0.1945,  ..., -0.1962, -0.4235, -0.2875],\n          [ 0.1698, -0.8609, -0.4359,  ...,  0.3350,  0.1756,  0.9231],\n          ...,\n          [-0.3097, -2.2208, -0.4807,  ..., -1.3168, -2.1752, -1.0567],\n          [-0.4007,  1.1555, -1.3430,  ..., -0.1299,  0.5212, -0.4273],\n          [-0.8204,  0.1182, -0.3734,  ..., -0.9046, -1.1273,  0.9913]],\n\n         [[ 0.3077, -1.0739,  0.2148,  ..., -1.3652, -1.6937, -0.0964],\n          [-1.6343,  1.0825, -1.6750,  ...,  0.7282,  0.1520, -0.1241],\n          [-0.1481, -1.7068, -0.3534,  ...,  0.2019, -0.9297, -1.2105],\n          ...,\n          [-0.7515,  1.2108,  0.9610,  ..., -1.3956,  0.8187,  0.6321],\n          [-0.4956, -0.8527,  0.7088,  ..., -1.1411, -0.6300,  0.3508],\n          [-1.3748, -0.2463, -1.0651,  ..., -0.0699, -0.2905, -1.0858]],\n\n         [[ 0.2502,  1.3549, -1.5098,  ...,  1.0487, -0.2245, -0.1314],\n          [ 0.3336,  0.9928,  0.1408,  ...,  1.2094,  0.6750, -1.4979],\n          [-1.4154,  1.6559, -1.1615,  ...,  0.9947, -0.5317,  0.4641],\n          ...,\n          [ 1.7152, -0.1027, -0.0812,  ..., -0.4163, -1.4394,  1.3101],\n          [-1.8432,  0.2402, -0.3617,  ..., -0.3868, -0.6380, -1.8943],\n          [-2.6075, -0.2024,  0.8287,  ..., -0.6683, -1.0884,  0.0150]]]])"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = torch.randn((1, 3,512,512), dtype=torch.float32)\n",
    "# x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 14, 512, 512])"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = resnet_model(x)\n",
    "# y.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-4         [-1, 64, 128, 128]               0\n",
      "            Conv2d-5         [-1, 64, 128, 128]          36,928\n",
      "       BatchNorm2d-6         [-1, 64, 128, 128]             128\n",
      "              ReLU-7         [-1, 64, 128, 128]               0\n",
      "            Conv2d-8         [-1, 64, 128, 128]          36,928\n",
      "       BatchNorm2d-9         [-1, 64, 128, 128]             128\n",
      "             ReLU-10         [-1, 64, 128, 128]               0\n",
      "            Block-11         [-1, 64, 128, 128]               0\n",
      "           Conv2d-12         [-1, 64, 128, 128]          36,928\n",
      "      BatchNorm2d-13         [-1, 64, 128, 128]             128\n",
      "             ReLU-14         [-1, 64, 128, 128]               0\n",
      "           Conv2d-15         [-1, 64, 128, 128]          36,928\n",
      "      BatchNorm2d-16         [-1, 64, 128, 128]             128\n",
      "             ReLU-17         [-1, 64, 128, 128]               0\n",
      "            Block-18         [-1, 64, 128, 128]               0\n",
      "           Conv2d-19          [-1, 128, 64, 64]          73,856\n",
      "      BatchNorm2d-20          [-1, 128, 64, 64]             256\n",
      "             ReLU-21          [-1, 128, 64, 64]               0\n",
      "           Conv2d-22          [-1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-23          [-1, 128, 64, 64]             256\n",
      "           Conv2d-24          [-1, 128, 64, 64]          73,856\n",
      "      BatchNorm2d-25          [-1, 128, 64, 64]             256\n",
      "             ReLU-26          [-1, 128, 64, 64]               0\n",
      "            Block-27          [-1, 128, 64, 64]               0\n",
      "           Conv2d-28          [-1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-29          [-1, 128, 64, 64]             256\n",
      "             ReLU-30          [-1, 128, 64, 64]               0\n",
      "           Conv2d-31          [-1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-32          [-1, 128, 64, 64]             256\n",
      "             ReLU-33          [-1, 128, 64, 64]               0\n",
      "            Block-34          [-1, 128, 64, 64]               0\n",
      "           Conv2d-35          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-36          [-1, 256, 32, 32]             512\n",
      "             ReLU-37          [-1, 256, 32, 32]               0\n",
      "           Conv2d-38          [-1, 256, 32, 32]         590,080\n",
      "      BatchNorm2d-39          [-1, 256, 32, 32]             512\n",
      "           Conv2d-40          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-41          [-1, 256, 32, 32]             512\n",
      "             ReLU-42          [-1, 256, 32, 32]               0\n",
      "            Block-43          [-1, 256, 32, 32]               0\n",
      "           Conv2d-44          [-1, 256, 32, 32]         590,080\n",
      "      BatchNorm2d-45          [-1, 256, 32, 32]             512\n",
      "             ReLU-46          [-1, 256, 32, 32]               0\n",
      "           Conv2d-47          [-1, 256, 32, 32]         590,080\n",
      "      BatchNorm2d-48          [-1, 256, 32, 32]             512\n",
      "             ReLU-49          [-1, 256, 32, 32]               0\n",
      "            Block-50          [-1, 256, 32, 32]               0\n",
      "           Conv2d-51          [-1, 512, 16, 16]       1,180,160\n",
      "      BatchNorm2d-52          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-53          [-1, 512, 16, 16]               0\n",
      "           Conv2d-54          [-1, 512, 16, 16]       2,359,808\n",
      "      BatchNorm2d-55          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-56          [-1, 512, 16, 16]       1,180,160\n",
      "      BatchNorm2d-57          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-58          [-1, 512, 16, 16]               0\n",
      "            Block-59          [-1, 512, 16, 16]               0\n",
      "           Conv2d-60          [-1, 512, 16, 16]       2,359,808\n",
      "      BatchNorm2d-61          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-62          [-1, 512, 16, 16]               0\n",
      "           Conv2d-63          [-1, 512, 16, 16]       2,359,808\n",
      "      BatchNorm2d-64          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-65          [-1, 512, 16, 16]               0\n",
      "            Block-66          [-1, 512, 16, 16]               0\n",
      "         Upsample-67        [-1, 512, 512, 512]               0\n",
      "           Conv2d-68        [-1, 256, 512, 512]       1,179,904\n",
      "           Conv2d-69        [-1, 128, 512, 512]         295,040\n",
      "           Conv2d-70         [-1, 64, 512, 512]          73,792\n",
      "           Conv2d-71         [-1, 14, 512, 512]             910\n",
      "================================================================\n",
      "Total params: 14,107,214\n",
      "Trainable params: 14,107,214\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 2276.00\n",
      "Params size (MB): 53.81\n",
      "Estimated Total Size (MB): 2332.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet_model,(3, 512, 512))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet_18(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU()\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Block(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (1): Block(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (layer2): Sequential(\n    (0): Block(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n      (identity_downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Block(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (layer3): Sequential(\n    (0): Block(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n      (identity_downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Block(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (layer4): Sequential(\n    (0): Block(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n      (identity_downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Block(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n  )\n  (upsample): Upsample(scale_factor=32.0, mode=bilinear)\n  (upconv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (upconv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (upconv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv_out): Conv2d(64, 14, kernel_size=(1, 1), stride=(1, 1))\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move the model to the device\n",
    "resnet_model.to(device)\n",
    "# next(resnet_model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training settings\n",
    "# parser = argparse.ArgumentParser(description='Information Removal at the bottleneck in Deep Neural Networks')\n",
    "# parser.add_argument('--batch-size', type=int, default=32, metavar='N',\n",
    "#                     help='input batch size for training (default: 32)')\n",
    "# parser.add_argument('--epochs', type=int, default=100, metavar='N',\n",
    "#                     help='number of epochs to train (default: 100)')\n",
    "# parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "#                     help='learning rate (default: 0.1)')\n",
    "# parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
    "# # parser.add_argument('--dev', default=\"cuda:0\")\n",
    "# parser.add_argument('--dev', default=\"cpu\")\n",
    "# parser.add_argument('--momentum-sgd', type=float, default=0.9, metavar='M',\n",
    "#                     help='Momentum')\n",
    "# parser.add_argument('--datapath', default='dataset/')\n",
    "# args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current testing block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-4         [-1, 64, 128, 128]               0\n",
      "            Conv2d-5         [-1, 64, 128, 128]          36,928\n",
      "       BatchNorm2d-6         [-1, 64, 128, 128]             128\n",
      "              ReLU-7         [-1, 64, 128, 128]               0\n",
      "            Conv2d-8         [-1, 64, 128, 128]          36,928\n",
      "       BatchNorm2d-9         [-1, 64, 128, 128]             128\n",
      "             ReLU-10         [-1, 64, 128, 128]               0\n",
      "            Block-11         [-1, 64, 128, 128]               0\n",
      "           Conv2d-12         [-1, 64, 128, 128]          36,928\n",
      "      BatchNorm2d-13         [-1, 64, 128, 128]             128\n",
      "             ReLU-14         [-1, 64, 128, 128]               0\n",
      "           Conv2d-15         [-1, 64, 128, 128]          36,928\n",
      "      BatchNorm2d-16         [-1, 64, 128, 128]             128\n",
      "             ReLU-17         [-1, 64, 128, 128]               0\n",
      "            Block-18         [-1, 64, 128, 128]               0\n",
      "           Conv2d-19          [-1, 128, 64, 64]          73,856\n",
      "      BatchNorm2d-20          [-1, 128, 64, 64]             256\n",
      "             ReLU-21          [-1, 128, 64, 64]               0\n",
      "           Conv2d-22          [-1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-23          [-1, 128, 64, 64]             256\n",
      "           Conv2d-24          [-1, 128, 64, 64]          73,856\n",
      "      BatchNorm2d-25          [-1, 128, 64, 64]             256\n",
      "             ReLU-26          [-1, 128, 64, 64]               0\n",
      "            Block-27          [-1, 128, 64, 64]               0\n",
      "           Conv2d-28          [-1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-29          [-1, 128, 64, 64]             256\n",
      "             ReLU-30          [-1, 128, 64, 64]               0\n",
      "           Conv2d-31          [-1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-32          [-1, 128, 64, 64]             256\n",
      "             ReLU-33          [-1, 128, 64, 64]               0\n",
      "            Block-34          [-1, 128, 64, 64]               0\n",
      "           Conv2d-35          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-36          [-1, 256, 32, 32]             512\n",
      "             ReLU-37          [-1, 256, 32, 32]               0\n",
      "           Conv2d-38          [-1, 256, 32, 32]         590,080\n",
      "      BatchNorm2d-39          [-1, 256, 32, 32]             512\n",
      "           Conv2d-40          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-41          [-1, 256, 32, 32]             512\n",
      "             ReLU-42          [-1, 256, 32, 32]               0\n",
      "            Block-43          [-1, 256, 32, 32]               0\n",
      "           Conv2d-44          [-1, 256, 32, 32]         590,080\n",
      "      BatchNorm2d-45          [-1, 256, 32, 32]             512\n",
      "             ReLU-46          [-1, 256, 32, 32]               0\n",
      "           Conv2d-47          [-1, 256, 32, 32]         590,080\n",
      "      BatchNorm2d-48          [-1, 256, 32, 32]             512\n",
      "             ReLU-49          [-1, 256, 32, 32]               0\n",
      "            Block-50          [-1, 256, 32, 32]               0\n",
      "           Conv2d-51          [-1, 512, 16, 16]       1,180,160\n",
      "      BatchNorm2d-52          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-53          [-1, 512, 16, 16]               0\n",
      "           Conv2d-54          [-1, 512, 16, 16]       2,359,808\n",
      "      BatchNorm2d-55          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-56          [-1, 512, 16, 16]       1,180,160\n",
      "      BatchNorm2d-57          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-58          [-1, 512, 16, 16]               0\n",
      "            Block-59          [-1, 512, 16, 16]               0\n",
      "           Conv2d-60          [-1, 512, 16, 16]       2,359,808\n",
      "      BatchNorm2d-61          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-62          [-1, 512, 16, 16]               0\n",
      "           Conv2d-63          [-1, 512, 16, 16]       2,359,808\n",
      "      BatchNorm2d-64          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-65          [-1, 512, 16, 16]               0\n",
      "            Block-66          [-1, 512, 16, 16]               0\n",
      "         Upsample-67        [-1, 512, 512, 512]               0\n",
      "           Conv2d-68        [-1, 256, 512, 512]       1,179,904\n",
      "           Conv2d-69        [-1, 128, 512, 512]         295,040\n",
      "           Conv2d-70         [-1, 64, 512, 512]          73,792\n",
      "           Conv2d-71         [-1, 14, 512, 512]             910\n",
      "================================================================\n",
      "Total params: 14,107,214\n",
      "Trainable params: 14,107,214\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 2276.00\n",
      "Params size (MB): 53.81\n",
      "Estimated Total Size (MB): 2332.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 7124, 20600) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mEmpty\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    989\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 990\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_data_queue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    991\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\multiprocessing\\queues.py\u001B[0m in \u001B[0;36mget\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    104\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 105\u001B[1;33m                         \u001B[1;32mraise\u001B[0m \u001B[0mEmpty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    106\u001B[0m                 \u001B[1;32melif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mEmpty\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-119-4151136027e0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m     \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mamp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautocast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\tqdm\\std.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1193\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1194\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1195\u001B[1;33m             \u001B[1;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1196\u001B[0m                 \u001B[1;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1197\u001B[0m                 \u001B[1;31m# Update and possibly print the progressbar.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    520\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 521\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    522\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    523\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1184\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1185\u001B[0m             \u001B[1;32massert\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_shutdown\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1186\u001B[1;33m             \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1187\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[1;33m-=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1188\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1150\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1151\u001B[0m             \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1152\u001B[1;33m                 \u001B[0msuccess\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_try_get_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1153\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0msuccess\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1154\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1001\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfailed_workers\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1002\u001B[0m                 \u001B[0mpids_str\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m', '\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpid\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mw\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfailed_workers\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1003\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpids_str\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1004\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mqueue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mEmpty\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1005\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 7124, 20600) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# iteration = 0\n",
    "# args.device = torch.device(args.dev)\n",
    "# if args.dev != \"cpu\":\n",
    "#     torch.cuda.set_device(args.device)\n",
    "# model = resnet_model.to(args.device)\n",
    "# args.criterion = torch.nn.BCEWithLogitsLoss().to(args.device)\n",
    "# args.optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum_sgd, weight_decay=args.weight_decay)\n",
    "#\n",
    "#\n",
    "# for data in tqdm(train_loader):\n",
    "#     inputs, labels = data[0].to(args.device), data[1].to(args.device)\n",
    "#     with torch.cuda.amp.autocast():\n",
    "#         print(labels.shape)\n",
    "#         # print(data[0])\n",
    "#         outputs = model(inputs)\n",
    "#         for i in range(5):\n",
    "#             print(outputs[i].size())\n",
    "#         # print(len(outputs))\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 22772, 13544) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mEmpty\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    989\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 990\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_data_queue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    991\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\multiprocessing\\queues.py\u001B[0m in \u001B[0;36mget\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    104\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 105\u001B[1;33m                         \u001B[1;32mraise\u001B[0m \u001B[0mEmpty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    106\u001B[0m                 \u001B[1;32melif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mEmpty\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-120-c5269a77b75f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSGD\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmomentum\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmomentum_sgd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight_decay\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight_decay\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m     \u001B[0miteration\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\tqdm\\std.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1193\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1194\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1195\u001B[1;33m             \u001B[1;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1196\u001B[0m                 \u001B[1;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1197\u001B[0m                 \u001B[1;31m# Update and possibly print the progressbar.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    520\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 521\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    522\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    523\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1184\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1185\u001B[0m             \u001B[1;32massert\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_shutdown\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1186\u001B[1;33m             \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1187\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[1;33m-=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1188\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1150\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1151\u001B[0m             \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1152\u001B[1;33m                 \u001B[0msuccess\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_try_get_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1153\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0msuccess\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1154\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1001\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfailed_workers\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1002\u001B[0m                 \u001B[0mpids_str\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m', '\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpid\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mw\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfailed_workers\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1003\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpids_str\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1004\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mqueue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mEmpty\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1005\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 22772, 13544) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# iteration = 0\n",
    "# args.device = torch.device(args.dev)\n",
    "# if args.dev != \"cpu\":\n",
    "#     torch.cuda.set_device(args.device)\n",
    "# model = resnet_model.to(args.device)\n",
    "# args.criterion = torch.nn.BCEWithLogitsLoss().to(args.device)\n",
    "# args.optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum_sgd, weight_decay=args.weight_decay)\n",
    "#\n",
    "# for data in tqdm(train_loader):\n",
    "#     iteration+=1\n",
    "#\n",
    "#     inputs, labels = data[0].to(args.device), data[1].to(args.device)\n",
    "#\n",
    "#\n",
    "#     with torch.cuda.amp.autocast():\n",
    "#         outputs=model(inputs)\n",
    "#         print(\"type outputs: \", type(outputs))\n",
    "#         print(\"tuple len: \", len(outputs))\n",
    "#         print(outputs[0].size())\n",
    "#         print(\"type outputs[1]: \", type(outputs[1]))\n",
    "#         print(outputs[-1].size())\n",
    "#         print(\"type labels: \", type(labels))\n",
    "#         print(labels.size())\n",
    "#\n",
    "#         # print(\"output size: \", outputs.size())\n",
    "#         # print(\"labels size: \", labels.size())\n",
    "#         loss = args.criterion(outputs[-1],labels)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### passed train and test function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mtemperancehong\u001B[0m (\u001B[33mteam_tout_gentil\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>E:\\E_Code\\segmentation_trial\\wandb\\run-20230622_100351-luh9xb3l</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/team_tout_gentil/LPCVC/runs/luh9xb3l' target=\"_blank\">prime-durian-6</a></strong> to <a href='https://wandb.ai/team_tout_gentil/LPCVC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/team_tout_gentil/LPCVC' target=\"_blank\">https://wandb.ai/team_tout_gentil/LPCVC</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/team_tout_gentil/LPCVC/runs/luh9xb3l' target=\"_blank\">https://wandb.ai/team_tout_gentil/LPCVC/runs/luh9xb3l</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]C:\\Users\\26236\\anaconda3\\envs\\Unet-tuto\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "def train(model, args, train_loader):\n",
    "    model.train()\n",
    "    running_loss=0\n",
    "    iteration=0\n",
    "    correct = 0\n",
    "    total=0\n",
    "\n",
    "    for data in tqdm(train_loader):\n",
    "        iteration+=1\n",
    "\n",
    "        # inputs, labels = data[0].to(args.device), data[1].to(args.device)\n",
    "        inputs, labels = data[0].to(args.device), data[1]\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs=model(inputs)\n",
    "            loss = args.criterion(outputs,labels)\n",
    "\n",
    "        args.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        args.optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "    train_loss=running_loss/len(train_loader)\n",
    "    # train_loss=running_loss/31  # 1021/32\n",
    "    accu=100.*correct/total\n",
    "\n",
    "\n",
    "    train_accu.append(accu)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print('Train Loss: %.3f | Accuracy: %.3f'%(train_loss,accu))\n",
    "    return(accu, train_loss)\n",
    "\n",
    "def test(model, args, val_loader):\n",
    "    model.eval()\n",
    "    running_loss=0\n",
    "    iteration=0\n",
    "    correct = 0\n",
    "    total=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(val_loader):\n",
    "            iteration+=1\n",
    "\n",
    "            inputs, labels = data[0].to(args.device), data[1].to(args.device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs=model(inputs)\n",
    "                loss = args.criterion(outputs,labels)\n",
    "\n",
    "            args.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            args.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "    test_loss=running_loss/len(val_loader)\n",
    "    # test_loss=running_loss/3  # 100/32\n",
    "    accu=100.*correct/total\n",
    "\n",
    "\n",
    "    eval_accu.append(accu)\n",
    "    eval_losses.append(test_loss)\n",
    "\n",
    "    print('Test Loss: %.3f | Accuracy: %.3f'%(test_loss,accu))\n",
    "    return(accu, test_loss)\n",
    "\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='Information Removal at the bottleneck in Deep Neural Networks')\n",
    "parser.add_argument('--batch-size', type=int, default=32, metavar='N',\n",
    "                    help='input batch size for training (default: 32)')\n",
    "parser.add_argument('--epochs', type=int, default=100, metavar='N',\n",
    "                    help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                    help='learning rate (default: 0.1)')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
    "# parser.add_argument('--dev', default=\"cuda:0\")\n",
    "parser.add_argument('--dev', default=\"cpu\")\n",
    "parser.add_argument('--momentum-sgd', type=float, default=0.9, metavar='M',\n",
    "                    help='Momentum')\n",
    "parser.add_argument('--datapath', default='dataset/')\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.device = torch.device(args.dev)\n",
    "if args.dev != \"cpu\":\n",
    "    torch.cuda.set_device(args.device)\n",
    "\n",
    "model = resnet_model.to(args.device)\n",
    "\n",
    "train_dataset = LPCVCDataset(datapath=args.datapath,transform=None,  n_class=14, train=True)\n",
    "# train_dataset = drone_dataset_train\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        # num_workers=2,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    ")\n",
    "\n",
    "# train_loader = train_loader\n",
    "\n",
    "val_dataset = LPCVCDataset(datapath=args.datapath, transform=None,  n_class=14, train=False)\n",
    "# val_dataset = drone_dataset_test\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        # num_workers=1,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    ")\n",
    "\n",
    "# val_loader = val_loader\n",
    "\n",
    "args.criterion = torch.nn.BCEWithLogitsLoss().to(args.device)\n",
    "args.optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum_sgd, weight_decay=args.weight_decay)\n",
    "\n",
    "train_accu = []\n",
    "train_losses = []\n",
    "\n",
    "eval_accu = []\n",
    "eval_losses = []\n",
    "\n",
    "# wandb.init(project=\"LPCVC\", entity='lpcvc')\n",
    "wandb.init(project=\"LPCVC\")\n",
    "wandb.run.name = \"resnet18_train\"\n",
    "wandb.config.epochs = args.epochs\n",
    "wandb.config.batch_size = args.batch_size\n",
    "wandb.config.learning_rate = args.lr\n",
    "wandb.config.weight_decay = args.weight_decay\n",
    "wandb.config.momentum = args.momentum_sgd\n",
    "wandb.config.train_dataset = train_dataset\n",
    "wandb.config.test_dataset = val_dataset\n",
    "# wandb.config.train_targets = train_dataset.targets\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs+1):\n",
    "    print('\\nEpoch : %d'%epoch)\n",
    "    train_acc, train_loss = train(model, args, train_loader)\n",
    "    test_acc, test_loss = test(model, args, val_loader)\n",
    "    wandb.log(\n",
    "        {\"train_acc\": train_acc, \"train_loss\": train_loss,\n",
    "        \"test_acc\": test_acc, \"test_loss\": test_loss})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Unet-tuto",
   "language": "python",
   "name": "unet-tuto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
